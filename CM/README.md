# CM (Collaborative Moving) Environment

ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“åä½œæ¬è¿ç¯å¢ƒï¼Œä¸“ä¸ºæµ‹è¯•å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„æ”¶æ•›æ€§è€Œè®¾è®¡ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒç®€ä»‹](#ç¯å¢ƒç®€ä»‹)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [å®‰è£…å’Œä½¿ç”¨](#å®‰è£…å’Œä½¿ç”¨)
- [ç¯å¢ƒè§„åˆ™](#ç¯å¢ƒè§„åˆ™)
- [é…ç½®é€‰é¡¹](#é…ç½®é€‰é¡¹)
- [APIæ–‡æ¡£](#apiæ–‡æ¡£)
- [ç¤ºä¾‹ä»£ç ](#ç¤ºä¾‹ä»£ç )
- [æ•™ç¨‹](#æ•™ç¨‹)
- [æµ‹è¯•](#æµ‹è¯•)

## ğŸ¯ ç¯å¢ƒç®€ä»‹

CMç¯å¢ƒæ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“åä½œä»»åŠ¡ï¼Œæ™ºèƒ½ä½“éœ€è¦åˆä½œå°†ä¸€ä¸ª2x2çš„ç®±å­æ¨åˆ°æŒ‡å®šçš„2x2ç›®æ ‡åŒºåŸŸã€‚ç¯å¢ƒè®¾è®¡ç®€æ´ä½†å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«é€‚åˆéªŒè¯MARLç®—æ³•çš„åŸºç¡€èƒ½åŠ›ã€‚

### æ¸¸æˆåœºæ™¯
- **ç½‘æ ¼ä¸–ç•Œ**ï¼š7x7ç½‘æ ¼ï¼ˆå¯é…ç½®ï¼‰
- **ç®±å­**ï¼šå æ®2x2æ ¼å­
- **ç›®æ ‡**ï¼š2x2çš„ç›®æ ‡åŒºåŸŸ
- **æ™ºèƒ½ä½“**ï¼š2-4ä¸ªæ™ºèƒ½ä½“ï¼ˆå¯é…ç½®ï¼‰

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¤ **åä½œæœºåˆ¶**ï¼šå¤šä¸ªæ™ºèƒ½ä½“ä»ä¸åŒä¾§é¢æ¨ç®±å­ï¼ŒæˆåŠŸç‡éšåä½œäººæ•°å¢åŠ 
- ğŸ® **ç®€å•æ“ä½œ**ï¼š5ä¸ªç¦»æ•£åŠ¨ä½œï¼ˆåœç•™ã€ä¸Šä¸‹å·¦å³ç§»åŠ¨ï¼‰
- ğŸ† **å›¢é˜Ÿå¥–åŠ±**ï¼šæ‰€æœ‰æ™ºèƒ½ä½“è·å¾—ç›¸åŒçš„å›¢é˜Ÿå¥–åŠ±
- âš™ï¸ **é«˜åº¦å¯é…ç½®**ï¼šæ”¯æŒå¤šç§éš¾åº¦çº§åˆ«å’Œè‡ªå®šä¹‰é…ç½®
- ğŸ”— **CTDEå…¼å®¹**ï¼šå®Œç¾æ”¯æŒQMIXã€VDNã€IQLç­‰ä¸»æµMARLç®—æ³•
- ğŸ“Š **ä¸°å¯Œè§‚æµ‹**ï¼šåŒ…å«è‡ªèº«ä½ç½®ã€ç®±å­ä½ç½®ã€ç›®æ ‡ä½ç½®å’Œå…¶ä»–æ™ºèƒ½ä½“ç›¸å¯¹ä½ç½®
- ğŸ¨ **å¯è§†åŒ–æ”¯æŒ**ï¼šæä¾›æ–‡æœ¬å’Œå›¾å½¢æ¸²æŸ“åŠŸèƒ½

## ğŸ“¥ å®‰è£…å’Œä½¿ç”¨

### åŸºç¡€ä½¿ç”¨

```python
from Env.CM import create_cm_env

# åˆ›å»ºç¯å¢ƒ
env = create_cm_env(difficulty="easy", render_mode="human")

# é‡ç½®ç¯å¢ƒ
observations, info = env.reset()

# æ‰§è¡ŒåŠ¨ä½œ
actions = {agent_id: env.get_avail_actions(agent_id)[0] for agent_id in env.agent_ids}
observations, rewards, terminated, truncated, info = env.step(actions)

# æ¸²æŸ“ç¯å¢ƒ
env.render()

# å…³é—­ç¯å¢ƒ
env.close()
```

### CTDEç¯å¢ƒï¼ˆç”¨äºMARLç®—æ³•ï¼‰

```python
from Env.CM import create_cm_ctde_env

# åˆ›å»ºCTDEç¯å¢ƒ
ctde_env = create_cm_ctde_env(
    difficulty="easy_ctde",
    global_state_type="concat"
)

# é‡ç½®ç¯å¢ƒï¼ˆè¿”å›å…¨å±€çŠ¶æ€ï¼‰
observations, global_state = ctde_env.reset()

# æ‰§è¡ŒåŠ¨ä½œ
actions = {agent_id: 0 for agent_id in ctde_env.agent_ids}
observations, rewards, terminated, truncated, info = ctde_env.step(actions)

# è·å–å…¨å±€çŠ¶æ€
current_global_state = info['global_state']

ctde_env.close()
```

## ğŸ® ç¯å¢ƒè§„åˆ™

### åä½œæ¨åŠ¨æœºåˆ¶
- **1ä¸ªæ™ºèƒ½ä½“æ¨åŠ¨**ï¼š50%æˆåŠŸç‡
- **2ä¸ªæ™ºèƒ½ä½“åä½œ**ï¼š75%æˆåŠŸç‡
- **3ä¸ªæ™ºèƒ½ä½“åä½œ**ï¼š90%æˆåŠŸç‡
- **4ä¸ªæ™ºèƒ½ä½“åä½œ**ï¼š100%æˆåŠŸç‡

### å¥–åŠ±æœºåˆ¶
- **æ—¶é—´æƒ©ç½š**ï¼š-0.01/æ­¥ï¼ˆé¼“åŠ±å¿«é€Ÿå®Œæˆï¼‰
- **ç¢°æ’æƒ©ç½š**ï¼š-0.1ï¼ˆæ™ºèƒ½ä½“ä¹‹é—´ç¢°æ’ï¼‰
- **åä½œå¥–åŠ±**ï¼š+0.02 Ã— åä½œäººæ•°
- **è·ç¦»å¥–åŠ±**ï¼šåŸºäºç®±å­ä¸ç›®æ ‡è·ç¦»çš„å˜åŒ–
- **ç›®æ ‡è¾¾æˆå¥–åŠ±**ï¼š+10.0

### åŠ¨ä½œç©ºé—´
- 0: STAYï¼ˆåœç•™ï¼‰
- 1: MOVE_UPï¼ˆå‘ä¸Šç§»åŠ¨ï¼‰
- 2: MOVE_DOWNï¼ˆå‘ä¸‹ç§»åŠ¨ï¼‰
- 3: MOVE_LEFTï¼ˆå‘å·¦ç§»åŠ¨ï¼‰
- 4: MOVE_RIGHTï¼ˆå‘å³ç§»åŠ¨ï¼‰

### è§‚æµ‹ç©ºé—´
æ¯ä¸ªæ™ºèƒ½ä½“çš„è§‚æµ‹åŒ…å«ï¼š
- è‡ªèº«ä½ç½® (x, y)
- ç®±å­ä¸­å¿ƒä½ç½® (x, y)
- ç›®æ ‡ä¸­å¿ƒä½ç½® (x, y)
- å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½®ï¼ˆæ¯ä¸ªæ™ºèƒ½ä½“2ç»´ï¼‰

## âš™ï¸ é…ç½®é€‰é¡¹

### é¢„å®šä¹‰éš¾åº¦

```python
from Env.CM import get_config_by_name

# å¯ç”¨é…ç½®
configs = ["easy", "normal", "hard", "debug", "cooperation_test",
           "single_agent", "multi_agent", "easy_ctde", "normal_ctde", "hard_ctde"]

# ä½¿ç”¨é…ç½®
config = get_config_by_name("easy")
env = create_cm_env_from_config(config)
```

### è‡ªå®šä¹‰é…ç½®

```python
from Env.CM import CMConfig, create_cm_env_from_config

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
custom_config = CMConfig(
    grid_size=9,           # ç½‘æ ¼å¤§å°
    n_agents=3,            # æ™ºèƒ½ä½“æ•°é‡
    max_steps=120,         # æœ€å¤§æ­¥æ•°
    push_success_probs={   # æ¨åŠ¨æˆåŠŸç‡
        1: 0.6, 2: 0.85, 3: 1.0, 4: 1.0
    },
    cooperation_reward=0.03,       # åä½œå¥–åŠ±
    goal_reached_reward=15.0      # ç›®æ ‡å¥–åŠ±
)

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
env = create_cm_env_from_config(custom_config)
```

## ğŸ“š APIæ–‡æ¡£

### ä¸»è¦å‡½æ•°

#### `create_cm_env(difficulty="normal", **kwargs)`
åˆ›å»ºåŸºç¡€CMç¯å¢ƒã€‚

**å‚æ•°ï¼š**
- `difficulty`ï¼šé¢„å®šä¹‰éš¾åº¦çº§åˆ«
- `**kwargs`ï¼šé…ç½®è¦†ç›–å‚æ•°

**è¿”å›ï¼š** CooperativeMovingEnvå®ä¾‹

#### `create_cm_ctde_env(difficulty="normal_ctde", global_state_type="concat", **kwargs)`
åˆ›å»ºCTDEå…¼å®¹ç¯å¢ƒã€‚

**å‚æ•°ï¼š**
- `difficulty`ï¼šCTDEä¼˜åŒ–çš„éš¾åº¦çº§åˆ«
- `global_state_type`ï¼šå…¨å±€çŠ¶æ€ç±»å‹ï¼ˆ"concat", "mean", "max", "attention"ï¼‰
- `**kwargs`ï¼šé…ç½®è¦†ç›–å‚æ•°

**è¿”å›ï¼š** CooperativeMovingCTDEEnvå®ä¾‹

### ç¯å¢ƒæ–¹æ³•

#### `reset(seed=None)`
é‡ç½®ç¯å¢ƒã€‚

**è¿”å›ï¼š**
- `observations`ï¼šå„æ™ºèƒ½ä½“çš„è§‚æµ‹
- `info`ï¼šç¯å¢ƒä¿¡æ¯

#### `step(actions)`
æ‰§è¡Œä¸€æ­¥ã€‚

**å‚æ•°ï¼š**
- `actions`ï¼šæ™ºèƒ½ä½“åŠ¨ä½œå­—å…¸

**è¿”å›ï¼š**
- `observations`ï¼šæ–°è§‚æµ‹
- `rewards`ï¼šå¥–åŠ±
- `terminated`ï¼šæ˜¯å¦ç»ˆæ­¢
- `truncated`ï¼šæ˜¯å¦æˆªæ–­
- `info`ï¼šç¯å¢ƒä¿¡æ¯

#### `get_avail_actions(agent_id)`
è·å–æ™ºèƒ½ä½“çš„å¯ç”¨åŠ¨ä½œã€‚

**å‚æ•°ï¼š**
- `agent_id`ï¼šæ™ºèƒ½ä½“ID

**è¿”å›ï¼š** å¯ç”¨åŠ¨ä½œåˆ—è¡¨

#### `render()`
æ¸²æŸ“ç¯å¢ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

#### `get_env_info()`
è·å–ç¯å¢ƒä¿¡æ¯ã€‚

**è¿”å›ï¼š** åŒ…å«ç¯å¢ƒå‚æ•°çš„å­—å…¸

## ğŸ’¡ ç¤ºä¾‹ä»£ç 

### å®Œæ•´å›åˆç¤ºä¾‹

```python
from Env.CM import create_cm_env
import numpy as np

def run_random_episode():
    env = create_cm_env(difficulty="easy")
    obs, info = env.reset()

    total_reward = 0
    steps = 0

    while steps < 100:
        # éšæœºé€‰æ‹©åŠ¨ä½œ
        actions = {}
        for agent_id in env.agent_ids:
            avail_actions = env.get_avail_actions(agent_id)
            actions[agent_id] = np.random.choice(avail_actions)

        # æ‰§è¡ŒåŠ¨ä½œ
        obs, rewards, terminated, truncated, info = env.step(actions)

        total_reward += list(rewards.values())[0]
        steps += 1

        print(f"Step {steps}: reward={list(rewards.values())[0]:.3f}, "
              f"distance={info['distance_to_goal']:.2f}")

        if terminated:
            print(f"Goal reached in {steps} steps!")
            break
        elif truncated:
            print("Episode truncated!")
            break

    env.close()
    return total_reward, steps

# è¿è¡Œç¤ºä¾‹
reward, steps = run_random_episode()
print(f"Episode result: reward={reward:.3f}, steps={steps}")
```

### ç®€å•åä½œæ™ºèƒ½ä½“

```python
from Env.CM import create_cm_env

class SimpleCooperativeAgent:
    def __init__(self, agent_id):
        self.agent_id = agent_id

    def choose_action(self, env, observations):
        obs = observations[self.agent_id]
        agent_x, agent_y = obs[0], obs[1]
        box_x, box_y = obs[2], obs[3]
        goal_x, goal_y = obs[4], obs[5]

        # ç®€å•ç­–ç•¥ï¼šå‘ç®±å­æ¨åŠ¨æ–¹å‘ç§»åŠ¨
        dx = goal_x - box_x
        dy = goal_y - box_y

        avail_actions = env.get_avail_actions(self.agent_id)

        if abs(dx) > abs(dy):  # ä¸»è¦åœ¨xæ–¹å‘æ¨åŠ¨
            if dx > 0 and 2 in avail_actions:
                return 2  # MOVE_DOWN
            elif dx < 0 and 1 in avail_actions:
                return 1  # MOVE_UP
        else:  # ä¸»è¦åœ¨yæ–¹å‘æ¨åŠ¨
            if dy > 0 and 4 in avail_actions:
                return 4  # MOVE_RIGHT
            elif dy < 0 and 3 in avail_actions:
                return 3  # MOVE_LEFT

        # éšæœºç§»åŠ¨
        move_actions = [a for a in [1, 2, 3, 4] if a in avail_actions]
        return np.random.choice(move_actions) if move_actions else 0

# ä½¿ç”¨åä½œæ™ºèƒ½ä½“
env = create_cm_env(difficulty="easy")
agents = [SimpleCooperativeAgent(agent_id) for agent_id in env.agent_ids]

obs, info = env.reset()
for step in range(50):
    actions = {agent.agent_id: agent.choose_action(env, obs) for agent in agents}
    obs, rewards, terminated, truncated, info = env.step(actions)

    if terminated:
        print(f"Cooperative agents reached goal in {step} steps!")
        break

env.close()
```

## ğŸ“– æ•™ç¨‹

è¯¦ç»†æ•™ç¨‹è¯·å‚è€ƒï¼š
- [CM_Tutorial.ipynb](./CM_Tutorial.ipynb) - å®Œæ•´çš„Jupyteræ•™ç¨‹
- [åä½œæ¬è¿æ¸¸æˆè®¾è®¡.md](../åä½œæ¬è¿æ¸¸æˆè®¾è®¡.md) - è®¾è®¡æ–‡æ¡£

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_env.py quick

# å®Œæ•´æµ‹è¯•å¥—ä»¶
python test_env.py comprehensive

# é…ç½®ç³»ç»Ÿæµ‹è¯•
python test_env.py config

# æœ€å°åŒ–æµ‹è¯•
python minimal_test.py
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

- **æ‰§è¡Œé€Ÿåº¦**ï¼š>1000 æ­¥/ç§’ï¼ˆdebugé…ç½®ï¼‰
- **å†…å­˜ä½¿ç”¨**ï¼š<100MBï¼ˆåŸºç¡€ç¯å¢ƒï¼‰
- **æ”¯æŒç®—æ³•**ï¼šQMIX, VDN, IQL, MADDPG, MAPPOç­‰
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒ1-4ä¸ªæ™ºèƒ½ä½“

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

## ğŸ”— ç›¸å…³é¡¹ç›®

- [DEMç¯å¢ƒ](../DEM/) - é˜²å¾¡ã€æŠ¤é€å’Œç§»åŠ¨ç¯å¢ƒ
- [HRGç¯å¢ƒ](../HRG/) - å¼‚æ„èµ„æºæ”¶é›†ç¯å¢ƒ
- [MSFSç¯å¢ƒ](../MSFS/) - å¤šæ™ºèƒ½ä½“æœç´¢æ•‘æ´ç¯å¢ƒ